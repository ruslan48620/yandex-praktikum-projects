{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта «Определение перспективного тарифа для телеком компании»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — Она сделана в предыдущем проекте.\n",
    "\n",
    "Построить модель с максимально большим значением *accuracy*. Необходимо довести долю правильных ответов до 0.75. Проверить *accuracy* на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *сalls* — количество звонков\n",
    "- *minutes* — суммарная длительность звонков в минутах\n",
    "- *messages* — количество sms-сообщений\n",
    "- *mb_used* — израсходованный интернет-трафик в Мб\n",
    "- *is_ultra* — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оглавление"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Открытие и изучение файла](#step1)\n",
    "2. [Разбиение данных на выборки](#step2)\n",
    "3. [Исследование модели](#step3)\n",
    "4. [Проверка модели на тестовой сборке](#step4)\n",
    "5. [Проверка модели на адекватность](#step5)\n",
    "6. [Общий вывод](#step6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step1\"></a>\n",
    "## 1. Открытие и изучение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подключение библиотек, необходимых модулей и алгоритмов\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58.0</td>\n",
       "      <td>344.56</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15823.37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.0</td>\n",
       "      <td>431.64</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3738.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>132.40</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21911.60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>43.39</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2538.67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.0</td>\n",
       "      <td>665.41</td>\n",
       "      <td>38.0</td>\n",
       "      <td>17358.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0\n",
       "5   58.0   344.56      21.0  15823.37         0\n",
       "6   57.0   431.64      20.0   3738.90         1\n",
       "7   15.0   132.40       6.0  21911.60         0\n",
       "8    7.0    43.39       3.0   2538.67         1\n",
       "9   90.0   665.41      38.0  17358.61         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# прочитаем данные из файла и выведем первые 10 строк\n",
    "users = pd.read_csv('users_behavior.csv')\n",
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['calls', 'minutes', 'messages', 'mb_used', 'is_ultra'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем названия столбцов таблицы\n",
    "users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# выведем общую информацию по таблице\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге проводилось первоначальное ознакомление с данными. Они были прочитаны из файла и сохранены в таблицу *users*. Была проведена базовая проверка данных на наличие пропусков, верного определения типов данных, правильного названия колонок в таблице. Все эти параметры определены правильно, ничего корректировать и исправлять не надо. Все готово для дальнейшей работы с таблицей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "## 2. Разбиение данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нашей задачи целевым признаком является признак `is_ultra`, который как раз и показывает, каким тарифом пользовался клиент в течение месяца. Выделим его в переменную `target`. Остальные признаки сохраним в переменной `features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = users.drop('is_ultra', axis=1)\n",
    "target = users['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с алгоритмами машинного обучения необходимо определить параметр рандомизации, который используется как начальное значение генератора псевдослучайных чисел. Чтобы зафиксировать одно определенное распределение при работе с данными, нужно использовать одно и то же значение пераметра `random_state`. Чтобы в дальнейшем не ошибиться при подстановке выбранного числа в методах для машинного обучения, сохраним его в переменной `rand_seed`, и в дальнейшем будем использовать его."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_seed = 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь необходимо разделить все данные на обучающую, валидационную и тестовые выборки. В нашей задаче спрятанной тестовой выборки нет, поэтому разделим исходные данные в отношении 3:1:1. Доли валидационной и тестовой выборок будут равны и составлять по 20%. Поскольку функция `train_test_split` делит только на 2 выборки, мы разделим данные в 2 этапа - сначала 3:2,а затем вторую часть данных пополам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отделим 40% данных для проверочных выборок\n",
    "features_train, features_check, target_train, target_check = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# определим 50% данных для валидационной выборки и 50% для тестовой выборки (из проверочной выборки)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_check, target_check, test_size=0.5, random_state=rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "\t features shape: (1928, 4)\n",
      "\t target shape: (1928,)\n",
      "Validation:\n",
      "\t features shape: (643, 4)\n",
      "\t target shape: (643,)\n",
      "Testing:\n",
      "\t features shape: (643, 4)\n",
      "\t target shape: (643,)\n"
     ]
    }
   ],
   "source": [
    "# Проверим, что данные распределены правильно\n",
    "print('Training:')\n",
    "print('\\t features shape:', features_train.shape)\n",
    "print('\\t target shape:', target_train.shape)\n",
    "\n",
    "print('Validation:')\n",
    "print('\\t features shape:', features_valid.shape)\n",
    "print('\\t target shape:', target_valid.shape)\n",
    "\n",
    "print('Testing:')\n",
    "print('\\t features shape:', features_test.shape)\n",
    "print('\\t target shape:', target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге проводилось разбиение данных на выборки: обучающую, валидационную и тестовую. Выборки были разделены в отношении 3:1:1, таким образом размеры выборок соотносятся 1928:643:643."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step3\"></a>\n",
    "## 3. Исследование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге необходимо исследовать различные модели с разными гиперпараметрами и выбрать ту, у которой доля правильных ответов будет наибольшей. Стоит задачи бинарной классификации. В качества моделей будем рассматривать решающее дерево, случайный лес и логистическую регрессию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с решающего дерева. В качестве исследуемых гиперпараметров возьмем максимальную глубину дерева (`max_depth`) в диапазоне от 1 до 10, минимальное количество примеров для разделения (`min_samples_split`) в диапазоне от 2 до 10, минимальное количество объектов в листе (`min_samples_leaf`) в диапазоне от 1 до 10. Сохраним модель и ее гиперпараметры для самой высокой доли правильный ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_dtc_accuracy = 0.8009331259720062\n",
      "best_dtc_depth = 8\n",
      "best_dtc_samples_split = 2\n",
      "best_dtc_samles_leaf = 3\n"
     ]
    }
   ],
   "source": [
    "# Определим первоначальные значения\n",
    "best_dtc_accuracy = 0\n",
    "best_dtc_model = None\n",
    "best_dtc_depth = 1\n",
    "best_dtc_samples_split = 2\n",
    "best_dtc_samles_leaf = 1\n",
    "\n",
    "# Проведем исследование\n",
    "for depth in range(1, 11):\n",
    "    for samples_split in range(2, 11):\n",
    "        for samles_leaf in range(1, 11):\n",
    "            model = DecisionTreeClassifier(\n",
    "                random_state=rand_seed, \n",
    "                max_depth=depth, \n",
    "                min_samples_split=samples_split, \n",
    "                min_samples_leaf=samles_leaf\n",
    "            )\n",
    "            model.fit(features_train, target_train)\n",
    "            accuracy = model.score(features_valid, target_valid)\n",
    "            if accuracy > best_dtc_accuracy:\n",
    "                best_dtc_model = model\n",
    "                best_dtc_accuracy = accuracy\n",
    "                best_dtc_depth = depth\n",
    "                best_dtc_samples_split = samples_split\n",
    "                best_dtc_samles_leaf = samles_leaf\n",
    "                \n",
    "print('best_dtc_accuracy =', best_dtc_accuracy)\n",
    "print('best_dtc_depth =', best_dtc_depth)\n",
    "print('best_dtc_samples_split =', best_dtc_samples_split)\n",
    "print('best_dtc_samles_leaf =', best_dtc_samles_leaf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее рассмотрим модель случайного леса. Здесь, в качестве гиперпараметров для исследования возьмем те же, что и для решающего дерева: `max_depth`, `min_samples_split`, `min_samples_leaf`. Также добавим исследование по количеству оценщиков (`n_estimators`), который будет изменяться в диапазоне от 2 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_rfc_accuracy = 0.8118195956454122\n",
      "best_rfc_depth = 9\n",
      "best_rfc_samples_split = 9\n",
      "best_rfc_samles_leaf = 3\n",
      "best_rfc_estimators = 10\n"
     ]
    }
   ],
   "source": [
    "# Определим первоначальные значения\n",
    "best_rfc_accuracy = 0\n",
    "best_rfc_model = None\n",
    "best_rfc_depth = 1\n",
    "best_rfc_samples_split = 2\n",
    "best_rfc_samles_leaf = 1\n",
    "best_rfc_estimators = 2\n",
    "\n",
    "# Проведем исследование\n",
    "for depth in range(1, 11):\n",
    "    for samples_split in range(2, 11):\n",
    "        for samles_leaf in range(1, 11):\n",
    "            for estimators in range(2, 11):\n",
    "                model = RandomForestClassifier(\n",
    "                    random_state=rand_seed, \n",
    "                    max_depth=depth, \n",
    "                    min_samples_split=samples_split, \n",
    "                    min_samples_leaf=samles_leaf,\n",
    "                    n_estimators=estimators\n",
    "                )\n",
    "                model.fit(features_train, target_train)\n",
    "                accuracy = model.score(features_valid, target_valid)\n",
    "                if accuracy > best_rfc_accuracy:\n",
    "                    best_rfc_model = model\n",
    "                    best_rfc_accuracy = accuracy\n",
    "                    best_rfc_depth = depth\n",
    "                    best_rfc_samples_split = samples_split\n",
    "                    best_rfc_samles_leaf = samles_leaf\n",
    "                    best_rfc_estimators = estimators\n",
    "                \n",
    "print('best_rfc_accuracy =', best_rfc_accuracy)\n",
    "print('best_rfc_depth =', best_rfc_depth)\n",
    "print('best_rfc_samples_split =', best_rfc_samples_split)\n",
    "print('best_rfc_samles_leaf =', best_rfc_samles_leaf)\n",
    "print('best_rfc_estimators =', best_rfc_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим также модель логистической регрессии. В данном случае рассмотрим работу модели для гиперпараметров по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_lr_accuracy = 0.6780715396578538\n"
     ]
    }
   ],
   "source": [
    "# Определим первоначальные значения\n",
    "best_lr_accuracy = 0\n",
    "best_lr_model = None\n",
    "\n",
    "# Проведем исследование\n",
    "    # solver='lbfgs' - указано, чтобы скрыть предупреждение об изменении значения solver по умолчанию\n",
    "model = LogisticRegression(random_state=rand_seed, solver='lbfgs')\n",
    "model.fit(features_train, target_train)\n",
    "accuracy = model.score(features_valid, target_valid)\n",
    "if accuracy > best_lr_accuracy:\n",
    "    best_lr_model = model\n",
    "    best_lr_accuracy = accuracy\n",
    "                \n",
    "print('best_lr_accuracy =', best_lr_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге были исследованы 3 модели для обучения. Доля правильных ответов выше всего получилась для модели случайного леса - 81%. Такое значение получилось для гиперпараметров: `max_depth`=9, `min_samples_split`=9, `min_samples_leaf`=3, `n_estimators`=10. При этом n_estimators бралось в небольшом диапазоне (до 10), по причине того, что проверка всех возможных вариантов занимает слишком много времени. Для решающего дерева доля правильных ответов получилась не сильно меньше - 80%. Но если мы получили результат лучше для первой модели за разумное время, лучше использовать первую модель для тестовых данных. Для логистической регрессии значение правильности получилось не столь высоким. Это связано с тем, что для нее не так подробно исследовались гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step4\"></a>\n",
    "## 4. Проверка модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге проверим работу модели, с наибольшим значением доли правильных ответов для валидационной выборки, на тестовых данных. Как мы выяснили на предыдущем шаге, такой моделью является модель случайного леса. Соответствующие гиперепараметры сохранены при исследовании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8227060653188181\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "        random_state=rand_seed, \n",
    "        max_depth=best_rfc_depth, \n",
    "        min_samples_split=best_rfc_samples_split, \n",
    "        min_samples_leaf=best_rfc_samles_leaf,\n",
    "        n_estimators=best_rfc_estimators\n",
    ")\n",
    "model.fit(features_train, target_train)\n",
    "accuracy = model.score(features_test, target_test)\n",
    "print(\"Accuracy =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из этого шага, для тестовой выборки значение доли правильных ответов получилось почти такое же (0,8227), как и для валидационной (0,8118). Это означает, что мы правильно подобрали гиперпараметры, и эту модель можно использовать в дальнейшем для предсказания тарифа по данным о поведении клиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step5\"></a>\n",
    "## 5. Проверка модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге проверим модель на вменяемость. Для этого узнаем сколько клиентов использует каждый тариф."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1332\n",
       "1     596\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что большинство клиентов использует тариф smart (потому что значению параметра is_ultra == 0 соответствует 1332 записи против 596 для is_ultra == 1). Обучим модель таким образом, чтобы она всегда предсказывала, что тариф будет smart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check accuracy = 0.7153965785381027\n"
     ]
    }
   ],
   "source": [
    "check_predictions = pd.Series(0, index=target_test.index)\n",
    "check_accuracy = accuracy_score(target_test, check_predictions)\n",
    "print(\"Check accuracy =\", check_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном шаге мы проверяли модель на адекватность. Для этого мы сравнили с ситуацией, когда модель всегда предсказывала бы что необходимо выбрать тариф smart. Как видно из результата, доля правильных ответов в данном случае соствляет 0,7154. Полученное значение для модели случайного леса выше, что показывает на эффективность выбранного решения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step6\"></a>\n",
    "## 6. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте проводилась бинарная классификация для выбора между двумя тарифами по данным о клиентах, которые уже используют их. Для выполнения этой задачи, первоначальная выборка была разбита на обучающую, валидационную и тестовую. Далее были определены параметры и целевой параметр. После чего проводилось исследование нескольких моделей с разными значениями гиперпараметров. При изучении были рассмотрены модели решающего дерева, случайного леса и логистической регрессии. В итоге была выбрана модель случайного леса для определенного набора гиперпараметров, как модель с самой высокой долей правильных ответов - 0,81. После чего, данная модель была проверена на тестовой сборке, правильность составила более 0.75, что является успешным результатом. После этого, модель была проверена на вменяемость, и рассмотрен случай, как если бы она всегда предсказывала только один тариф. Доля правильных ответов для данного случая составила 0,72, это показывает, что полученная в ходе иследования модель - адекватна."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
